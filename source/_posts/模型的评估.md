---
title: 模型的评估
date: 2016-04-15 15:46:09
tags:
- 机器学习
- 更新中
---

<!--more-->

### 训练集与测试集

在模式识别（pattern recognition）与机器学习（machine learning）的相关研究中，经常会将数据集（dataset）分为训练集（training set）跟测试集（testing set）这两个子集，前者用以建立模型（model），后者则用来评估该模型对未知样本进行预测时的精确度，正规的说法是泛化能力（generalization ability）。怎么将完整的数据集分为训练集跟测试集，必须遵守如下要点：

1. **只有训练集才可以用在模型的训练过程中，测试集则必须在模型完成之后才被用来评估模型优劣的依据。**
2. **训练集中样本数量必须够多，一般至少大于总样本数的50%。**
3. **两组子集必须从完整集合中均匀取样。**

- 其中最后一点特别重要，均匀取样的目的是希望减少训练集/测试集与完整集合之间的偏差（bias），但却也不易做到。一般的作法是随机取样，当样本数量足够时，便可达到均匀取样的效果


### **交叉验证法(Cross Validation)**

- `基本思想` : 尽可能保证数据分布的一致性, 一般通过分层采样将原始数据（dataset）分为k个子集，每次用k-1个子集的并集作为训练集（training set）, 余下的那个子集做为，另一部分做为验证集（validation set）,也叫测试集，这样就可以获得k组训练/测试数据, 就可以进行k次训练, 最后返回k个结果的均值.

- **具体实现过程**

  ![10折交叉验证](/img/模型的评估/cv.png)

  - 由图可知, 我们将原始数据通过分层抽样分为10组, 每次将其中一组作为测试集, 剩余九组作为训练集去训练模型,      这样得到10个模型的测试结果, 最后返回10个测试结果的`均值`

